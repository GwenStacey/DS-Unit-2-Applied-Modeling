{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Glob in my dataframes\n",
    "SOURCE = '../competition_data/'\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "data = {}\n",
    "for path in glob(SOURCE + '*.csv'):\n",
    "    df = pd.read_csv(path)\n",
    "    filename = path.split('/')[-1]\n",
    "    filename2 = filename.split('\\\\')[1]\n",
    "    name = filename2.split('.')[0]\n",
    "    data[name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bill_of_materials', 'components', 'comp_adaptor', 'comp_boss', 'comp_elbow', 'comp_float', 'comp_hfl', 'comp_nut', 'comp_other', 'comp_sleeve', 'comp_straight', 'comp_tee', 'comp_threaded', 'sample_submission', 'specs', 'test_set', 'train_set', 'tube', 'tube_end_form', 'type_component', 'type_connection', 'type_end_form'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check our work\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainval = data['train_set']\n",
    "test = data['test_set']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainval_tube_assemblies = trainval['tube_assembly_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split trainval array based on unique ids\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_tube_assemblies, val_tube_assemblies = train_test_split(trainval_tube_assemblies, random_state =42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ensure no matching ids\n",
    "set(train_tube_assemblies)&set(val_tube_assemblies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22628, 8), (7585, 8), (30213, 8))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Establish train and val dataframes\n",
    "train = trainval[trainval['tube_assembly_id'].isin(train_tube_assemblies)]\n",
    "val = trainval[trainval['tube_assembly_id'].isin(val_tube_assemblies)]\n",
    "#Ensure shapes equal to trainval shape\n",
    "train.shape, val.shape, trainval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def clean_it_up(X):\n",
    "    X = X.copy()\n",
    "    \n",
    "    #Convert quote date to datetime create month and year feature\n",
    "    X['quote_date'] = pd.to_datetime(X['quote_date'], infer_datetime_format = True)\n",
    "    X['quote_year'] = X['quote_date'].dt.year\n",
    "    X['quote_month'] = X['quote_date'].dt.month\n",
    "    X = X.drop(columns = 'quote_date')\n",
    "    \n",
    "    #Merge in tube\n",
    "    tube = data['tube']\n",
    "    X = X.merge(tube, how = 'left')\n",
    "    \n",
    "    #Engineer features from bill_of_materials\n",
    "    materials = data['bill_of_materials']\n",
    "    \n",
    "    materials['components_total'] = (materials['quantity_1'].fillna(0) + \n",
    "                                     materials['quantity_2'].fillna(0) + \n",
    "                                     materials['quantity_3'].fillna(0) + \n",
    "                                     materials['quantity_4'].fillna(0) + \n",
    "                                     materials['quantity_5'].fillna(0) + \n",
    "                                     materials['quantity_6'].fillna(0) + \n",
    "                                     materials['quantity_7'].fillna(0) + \n",
    "                                     materials['quantity_8'].fillna(0))\n",
    "    \n",
    "    materials['components_distinct'] = (materials['component_id_1'].notnull().astype(int) + \n",
    "                                        materials['component_id_2'].notnull().astype(int) + \n",
    "                                        materials['component_id_3'].notnull().astype(int) + \n",
    "                                        materials['component_id_4'].notnull().astype(int) + \n",
    "                                        materials['component_id_5'].notnull().astype(int) + \n",
    "                                        materials['component_id_6'].notnull().astype(int) + \n",
    "                                        materials['component_id_7'].notnull().astype(int) + \n",
    "                                        materials['component_id_8'].notnull().astype(int))\n",
    "    \n",
    "    #Merge in just the new features\n",
    "    features = ['tube_assembly_id','component_id_1', 'components_total', 'components_distinct']\n",
    "    X = X.merge(materials[features], how = 'left')\n",
    "    \n",
    "    #Get component_type_id, lower cardinality than component_type\n",
    "    components = data['components']\n",
    "    components = components.rename(columns={'component_id':'component_id_1'})\n",
    "    features = ['component_id_1', 'component_type_id']\n",
    "    X = X.merge(components[features], how = 'left')\n",
    "    \n",
    "    #Get total of specs for tubes\n",
    "    specs = data['specs']\n",
    "    specs['specs_total'] = specs.drop(columns = ['tube_assembly_id']).count(axis = 1)\n",
    "    features = ['tube_assembly_id', 'specs_total', 'spec1']\n",
    "    X = X.merge(specs[features], how = 'left')\n",
    "    \n",
    "    #Drop tube_assembly_id because goal is to predict unknown assemblies\n",
    "    X = X.drop(columns = 'tube_assembly_id')\n",
    "    \n",
    "    return X\n",
    "\n",
    "train = clean_it_up(train)\n",
    "val = clean_it_up(val)\n",
    "test = clean_it_up(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arrange into X features and y target\n",
    "target = 'cost'\n",
    "X_train = train.drop(columns = target)\n",
    "X_val = val.drop(columns =target)\n",
    "X_test = test.drop(columns = 'id')\n",
    "\n",
    "y_train = train[target]\n",
    "y_val = val[target]\n",
    "#Log transformed for possible later use\n",
    "y_train_log = np.log1p(y_train)\n",
    "y_val_log = np.log1p(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:38:42] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Validation Error : 0.2719603739172016\n"
     ]
    }
   ],
   "source": [
    "#Make pipeline\n",
    "from xgboost import XGBRegressor\n",
    "pipeline = make_pipeline(ce.OrdinalEncoder(),\n",
    "                         XGBRegressor(n_estimators = 1000, \n",
    "                                               n_jobs = -1))\n",
    "#Fit pipeline\n",
    "pipeline.fit(X_train, y_train_log)\n",
    "\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
    "\n",
    "#Predict\n",
    "y_pred = pipeline.predict(X_val)\n",
    "print(f'Validation Error : {rmse(y_val_log, y_pred)}')\n",
    "\n",
    "def generate_submission(estimator, X_test, filename):\n",
    "    y_pred_log = estimator.predict(X_test)\n",
    "    y_pred = np.expm1(y_pred_log)\n",
    "    submission = data['sample_submission']\n",
    "    submission['cost'] = y_pred\n",
    "    submission.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_submission(pipeline, X_test, 'submission1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
